{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "141181b9",
   "metadata": {},
   "source": [
    "## Data quality selection notebook\n",
    "\n",
    "This run selection tool looks for good quality runs for the requested sky region, range of zenith and NSB conditions (NOTE: the default selection cuts are valid for low NSB observations).\n",
    "\n",
    "The default cuts are to some extent, arbitrary - obviously, runs which barely fail to be selected are not totally useless... so, depending on the goal of an analysis it may be wise to relax (or tighten) the selection. For example, cuts could be softer if the goal is just source detection.\n",
    "\n",
    "The default cuts set below are intended to provide a good quality low-NSB sample for flux calculations (energy spectrum, light curve), while keeping systematic errors related to variable performance an atmospheric conditions at an *acceptable* level. The selection is not the same as in the LST1 performance paper (ApJ 956), but it should provide data of about the same quality.\n",
    "\n",
    "Note that the selection here is performed at the run level but, as can be clearly seen below, we could benefit of a selection at the level of a subrun, or even based on shorter time periods (the approach that will be followed by CTA). This however is probably something to be introduced at a higher stage of the analysis, likely in the DL2 to DL3 stage\n",
    "\n",
    "### Cosmics intensity spectra\n",
    "The selection is based on the **differential intensity spectra of the detected showers, dR/dI (events / s / p.e.)** , where intensity is the image intensity, total number of p.e. in pixels which survive image cleaning.\n",
    "These spectra are computed on a subrun-wise basis (as part of the DL1 data check). The idea is that at intensities well above the camera threshold, the rate of cosmics, for optimal atmospheric conditions and nominal telescope performance, should depend mainly on the telescope pointing (with perhaps some small yearly modulation due to seasonal atmospheric variations). If, all other things being equal, we modify the amount of recorded light (e.g. because of a lower telescope throughput, or a higher-than-usual atmospheric absorption) we will not record fewer \"high-intensity\" showers (unless the reduction of light is so strong as to go all the way down to the threshold): all those high-intensity showers will still trigger, but will be recorded at a lower intensity. The dR/dI spectrum in that high-intensity region will shift to lower values.\n",
    "\n",
    "We have characterized the high-intensity dR/dI spectra with a power-law fit between 316 and 562 p.e. (these are edges of the intensity histogram binning in the DL1 data check). The fit parameters (normalization and index) have clear zenith-distance dependencies that we have corrected, to get \"ZD=0-equivalent\" values. We then compute, from this ZD-corrected fits, the value of dR/dI in the middle of the fit range (422 p.e.). This value, and the power-law index, are used to judge whether a given run looks \"of good quality\" or not. \n",
    "\n",
    "Since we have these parameters for every subrun, we also use their variability of the quantities through a run as a proxy for data quality. We obtain a Lomb-Scargle periodogram of dR/dI@422 p.e. to spot runs with unstable behaviour. The original idea was to use this to spot periodic increases of rate due to the MAGIC LIDAR. It is not clear if it is the best way to do this. For now, we just compute the maximum amplitude in the LS periodogram (of the dRdI vs. time) of the run as a selection parameter, cutting the tail of the distribution (see below).\n",
    "\n",
    "\n",
    "### Outline of the selection procedure:\n",
    "\n",
    "* The user sets \n",
    "    * the desired Sky Region (e.g. for wobble observations of a given source)\n",
    "    * the range of dates (in YYYYMMDD format)\n",
    "    * the zenith distance range\n",
    "    * the maximum allowed NSB level\n",
    "\n",
    "Then the following additional criteria are used to determine what a good run is:\n",
    "\n",
    "* the run must contain interleaved flatfield and pedestal events (only runs with no interleaved **at all** are rejected)\n",
    "<br>\n",
    "\n",
    "* the pointing (in sky coordinates) must be stable (details can be found below)\n",
    "<br>\n",
    "* the mean P-value of the dR/dI power-law fit (for all subruns in a run) must be above a given threshold (to exclude bad fits). The cut value depends on the number of subruns, see details later in the notebook.\n",
    "<br>\n",
    "* the maximum amplitude of the Lomb-Scargle periodogram of dR/dI@422 p.e. through the run must be below a given value (just to exclude very unstable runs). NOTE: some high values may be due to the periodic shots of the MAGIC LIDAR, in that case they might be recoverable, since down the pipeline the LIDAR-induced events are very gamma-unlike and easily identified.\n",
    "<br>\n",
    "* the fitted power-law index of dR/dI (mean in run) must be within a given range (see default cut values later in the notebook)\n",
    "<br>\n",
    "* dR/dI@422 p.e. (mean in run) must above a certain value (1.5 events/s/p.e. by default), and 80% of the subrun-wise values must be contained in a range of 0.15 around the most frequent value (mode) in the run.\n",
    "<br>\n",
    "* the so-called intensity threshold (value of intensity for which dR/dI reaches half of the peak for cosmics) is below a given value (see below in the notebook). This is a proxy for energy threshold (for a given zenith). The default cut is not tight, because even data with high threshold may be of very good quality, and valid to obtain a spectrum. Only when one is targeting very low energies (e.g. for pulsar analysis) then it may be necessary to make a stricter selection than the default one.\n",
    "\n",
    "\n",
    "Optimistic note: if we ever have **data in which the event rate is dominated by gammas**, one should be careful with the data selection... the assumption is that the rate of cosmics is **completely dominated by protons** and other nuclei!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48deaf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from astropy.coordinates import SkyCoord, AltAz, angular_separation\n",
    "import astropy.units as u\n",
    "from scipy.stats import binned_statistic\n",
    "from scipy.signal import lombscargle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad42b137-7f64-420f-aa76-1e2489aef969",
   "metadata": {},
   "source": [
    "## USER INPUT: define below which version(s) of the DL1 files you intend to use in your analysis\n",
    "Note: if you are not running the notebook in a system where the DL1 files are accessible, just set dl1_dirlist to None in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97b002c-9d09-436f-8a2d-1da8843cfd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is in order of preference. In this case we state that we want to use v0.10, but if it is \n",
    "# not available we will use v0.9. Typically one wants to use the latest available version, and \n",
    "# default to the previous one if the latest is not available.\n",
    "dl1_dirlist = [\"/fefs/aswg/data/real/DL1/YYYYMMDD/v0.10/tailcut84\",\n",
    "               \"/fefs/aswg/data/real/DL1/YYYYMMDD/v0.9/tailcut84\"]\n",
    "\n",
    "# YYYYMMDD of course stands for the night's date (by convention, the date before midnight)\n",
    "\n",
    "# Uncomment the line below in case you are not running in the IT cluster, and the DL1 files are not available\n",
    "# anywhere in the system where you are running.\n",
    "# dl1_dirlist = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb43e081",
   "metadata": {},
   "source": [
    "## USER INPUT: path to the necessary datacheck files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3fcad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: the sample of night-wise datacheck files from November 2019 to January 2024 is ~3.2 GB \n",
    "#\n",
    "# The standard path for the (v0.10) night-wise datacheck files at the IT cluster is \n",
    "# /fefs/aswg/data/real/OSA/DL1DataCheck_LongTerm/v0.10/YYYYMMDD/\n",
    "#\n",
    "# Example: load all the 2023 files processed with v0.10:\n",
    "# files = glob.glob(\"/fefs/aswg/data/real/OSA/DL1DataCheck_LongTerm/v0.10/2023????/DL1_datacheck_2023*.h5\")\n",
    "#\n",
    "\n",
    "files = glob.glob(\"/fefs/aswg/workspace/analysis-school-2024/DL1_datacheck/night_wise/DL1_datacheck_2022*.h5\")\n",
    "files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1ce156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes a few minutes... DON'T RUN IT MORE THAN ONCE, it is not needed! (If you change the \n",
    "# sky region or the cuts just execute the cells from \"Data selection configuration\" onwards)\n",
    "dummy = []\n",
    "dummy2 = []\n",
    "dummy3 = []\n",
    "\n",
    "missing_flatfield_tables = 0\n",
    "\n",
    "for i, file in enumerate(files):\n",
    "    if i%10 == 0:\n",
    "        print(i, '/', len(files), file)\n",
    "    dummy.append(pd.read_hdf(file, 'cosmics_intensity_spectrum'))\n",
    "    dummy2.append(pd.read_hdf(file, 'runsummary'))\n",
    "    \n",
    "    try:\n",
    "        fftable = pd.read_hdf(file, 'flatfield', errors='ignore')\n",
    "        dummy3.append(fftable)\n",
    "    except: \n",
    "        # some check files have no flatfield table at all (if calibox was off) \n",
    "        missing_flatfield_tables += 1\n",
    "\n",
    "# cosmics intensity spectra table (subrun-wise):\n",
    "cis = pd.concat(dummy, ignore_index=True)\n",
    "\n",
    "# flatfield table (subrun-wise):\n",
    "flatfield = pd.concat(dummy3, ignore_index=True)\n",
    "\n",
    "# parameters computed run-wise:\n",
    "runsummary = pd.concat(dummy2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba15213e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cis.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136ce3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatfield.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fa2873",
   "metadata": {},
   "outputs": [],
   "source": [
    "runsummary.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53373bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain list of runnumbers and corresponding dates:\n",
    "runlist, iix = np.unique(cis['runnumber'], return_index=True)\n",
    "rundate = cis['yyyymmdd'][iix].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef020a41",
   "metadata": {},
   "source": [
    "## We will now compute some run-wise quantities from the subrun-wise table entries  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2976da12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Lomb-Scargle periodogram of ZD_corrected_cosmics_rate_at_422_pe vs. time\n",
    "# May eventually be useful to identify runs affected by MAGIC LIDAR shots...\n",
    "#\n",
    "\n",
    "max_lsc = []\n",
    "max_lsc_period = [] # in seconds\n",
    "for i, ri in enumerate(runlist):\n",
    "    if i%1000 == 0:\n",
    "        print(i, '/', len(runlist))\n",
    "    rvalues = cis['ZD_corrected_cosmics_rate_at_422_pe'][cis['runnumber']==ri].to_numpy()\n",
    "    tvalues = cis['time'][cis['runnumber']==ri].to_numpy()\n",
    "    tvalues -= tvalues[0]\n",
    "    freqs = np.logspace(-3, -1, 100)\n",
    "    mask = ~np.isnan(rvalues)\n",
    "    lsc = lombscargle(tvalues[mask], rvalues[mask], freqs, \n",
    "                      normalize=True, precenter=True)\n",
    "    max_lsc.append(np.nanmax(lsc))\n",
    "    if (~np.isnan(lsc)).sum() == 0:\n",
    "        max_lsc_period.append(np.nan)\n",
    "    else:\n",
    "        max_lsc_period.append(1./freqs[np.nanargmax(lsc)])\n",
    "\n",
    "max_lsc = np.array(max_lsc)\n",
    "max_lsc_period = np.array(max_lsc_period)\n",
    "\n",
    "# You may get some RuntimeWarnings, from rare data with big issues - those warnings can be safely ignored"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548a05e5",
   "metadata": {},
   "source": [
    "## ****************   Data selection configuration   ****************\n",
    "For a standard selection of dark-night data, just set the desired source coordinates, the zenith angle range (if desired), and the time span of the data in YYYYMMDD. All the rest can be kept at the default values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9341ace8",
   "metadata": {},
   "source": [
    "## USER INPUT: put source coordinates below (if set to None, all data will be used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f47802",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_coordinates = None\n",
    "\n",
    "# Source coordinates can be set to specific RA, dec values, or using the source name (if known to astropy):\n",
    "source_coordinates = SkyCoord.from_name(\"Crab Nebula\")\n",
    "# source_coordinates = SkyCoord.from_name(\"Mrk 501\")\n",
    "# source_coordinates = SkyCoord.from_name(\"BL Lac\")\n",
    "\n",
    "print('Source coordinates:', source_coordinates)\n",
    "\n",
    "# Select here the desired range of telescope pointings around the source. \n",
    "# The values below are for *standard* wobble observations (0.4 deg source offset)\n",
    "min_angle_to_source = 0.35 * u.deg\n",
    "max_angle_to_source = 0.45 * u.deg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3ace3c",
   "metadata": {},
   "source": [
    "## USER INPUT: zenith distance range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6806267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just an example, use whatever you need\n",
    "min_zenith = 0 * u.deg\n",
    "max_zenith = 50 * u.deg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e905a5",
   "metadata": {},
   "source": [
    "## USER INPUT: range of dates YYYYMMDD (in \"date before midnight\" convention) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4296dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first_date = 0         # no selection\n",
    "# last_date  = 29990101  # no selection\n",
    "\n",
    "# Both first_date and last_date are included in the selection:\n",
    "first_date = 20201101\n",
    "last_date  = 20231231\n",
    "# Of course, the input sample of datacheck files must cover the range of dates you are interested in! \n",
    "\n",
    "\n",
    "# Very stable period, for reference: 20221118 - 20230214"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4d5c60",
   "metadata": {},
   "source": [
    "## USER INPUT: maximum diffuse NSB (average std dev of charge of pedestals, in pixels with no nearby bright star)\n",
    "Below we are selecting by default \"dark conditions\" (i.e. not too high NSB like you can have from the moon being above the horizon). Of course, some data are taken in moon conditions, or on a particularly bright sky field, so the value may have to be adapted to the data in question... \n",
    "\n",
    "For data taken with **very high** NSB, also the trigger threshold of the LST may be significantly higher, and in that case one may need to relax with the so-called \"intensity threshold\" cut that you will find a few cells below (\"max_intensity_at_half_peak_rate\", which is the intensity at which 50% of the dR/dI peak rate is reached). By default it is set to remove runs in which the telescope threshold is too high, but this may be the case for all your data (e.g., for a GRB observed only in moon conditions) and hence you may be forced to remove of relax the cut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed08ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_diffuse_nsb_std = 2.3 # p.e. A maximum value of 2.3 roughly corresponds to selecting moon-less data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474d27df",
   "metadata": {},
   "source": [
    "## End of user input\n",
    "For a standard data selection there is no need to modify anything else.\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c0eba8",
   "metadata": {},
   "source": [
    "## Require that data contain interleaved and pedestal events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca366b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic selection: select only runs with in which both types of interleaved events are present:\n",
    "require_interleaved_pedestals = True\n",
    "require_interleaved_flatfield = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49b5bad",
   "metadata": {},
   "source": [
    "## Pointing stability (maximum allowed std dev of declination in run)\n",
    "Besides runs with unstable pointing, this will also remove runs in which tracking got stuck (if not already removed by the source selection above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc40ad24",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pointing_dec_std = 0.01 # deg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6002402e",
   "metadata": {},
   "source": [
    "## Selection based on the dR/dI, differential cosmics rate (in intensity), i.e. \"Cherenkov transparency\"\n",
    "As part of the DL1 data checks, dR/dI was fitted to a power-law between 316-562 p.e. (the funny values are due to the binning used in the DL1 datacheck to store the intensity histograms). The fit parameters were then \"converted\" to their ZD=0 equivalent, i.e. we apply a zenith-dependent correction so the values for good data are all around the same values.\n",
    "\n",
    "Then we use the (ZD-corrected) power-law index at 422 p.e., and the (ZD-corrected) vaue of dR/dI (events per second and per p.e.) at 422 p.e. as quantities for the quality selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91f0ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We make a fit per subrun. Then we average the fit p-values. For good fits the pdf of P us uniform in [0,1]\n",
    "# The mean will have mean 0.5 and std dev 1/sqrt(12*Nsubruns). \n",
    "# We require a minimum value of (mean_p-0.5)*sqrt(12*Nsubruns) (in the limit of large Nsubruns would be a standard\n",
    "# gaussian of mean 0 and std dev 1)\n",
    "\n",
    "min_mean_fit_p = -3.\n",
    "\n",
    "# Lomb Scargle periodogram, to detect strange features in the dR/dI evolution within a run\n",
    "max_LS_periodogram_maxamplitude = 1e-2\n",
    "\n",
    "min_drdi_index = -2.35\n",
    "max_drdi_index = -2.1\n",
    "\n",
    "min_drdi_at_422pe = 1.5\n",
    "# We do not set a maximum for the rate, we expect all bad observation (or telescope) conditions \n",
    "# to result in lower-than-optimal rates\n",
    "\n",
    "# Minimum fraction of subruns around the mode of drdi_at_422pe (within +/-0.075) - see the find_mode \n",
    "# function below\n",
    "min_fraction_around_mode = 0.8\n",
    "\n",
    "# Maximum intensity threshold\n",
    "# This is a proxy for energy threshold (for a given zenith). the cut is not tight, because\n",
    "# even data with high threshold may be of very good quality, and valid to obtain a spectrum.\n",
    "# If one is targeting very low energies (e.g. for pulsar analysis) then it may be necessary to \n",
    "# make a stricter selection.\n",
    "max_intensity_at_half_peak_rate = 70 # p.e.\n",
    "\n",
    "# Note: The cut in intensity applied in the analyis of low-threshold (<40) data is >50 p.e. \n",
    "# The cut should be higher (to prevent biases in flux calculations) for data with higher threshold.\n",
    "# Difficult to set a general rule, but it is safer to put the cut above the peak of the cosmics \n",
    "# intensisy spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d86853",
   "metadata": {},
   "source": [
    "## ********* End of Configuration ************\n",
    "##\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f551f34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total number of loaded subruns:', len(cis))\n",
    "print('Total number of loaded runs:', len(np.unique(cis['runnumber'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6aa9f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remove runs in summary table which are not present in the cis table, to keep consistency between them.\n",
    "# NOTE, AM 20231117: as of now only run 8091 is missing from the cis table, because \n",
    "# its original run-wise datacheck file is faulty (possibly due to some problem at run time)\n",
    "\n",
    "for r in runsummary['runnumber']:\n",
    "    if r in runlist:\n",
    "        continue\n",
    "    print('Removing run', r, 'from runsummary table!')\n",
    "    \n",
    "    runsummary = runsummary.drop(np.where(runsummary['runnumber']==r)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401ce371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that now the runsummary entries match the runs in runlist (in the same order)\n",
    "assert(np.allclose(runlist, runsummary['runnumber']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9429ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some utility functions:\n",
    "#\n",
    "# Function to find the mode (most frequent value) of an array x, using a bin width bw \n",
    "# and step dx (default=bw/100) (it is a sliding window sum)\n",
    "#\n",
    "# If return_fraction==True, then the fraction of the array's elements\n",
    "# contained in the bw-wide window around the mode is returned (instead of the \n",
    "# mode)\n",
    "#\n",
    "def find_mode(x, bw=0.15, dx=None, return_fraction=False):\n",
    "    \n",
    "    min = np.nanmin(x)\n",
    "    max = np.nanmax(x)\n",
    "    \n",
    "    if np.isnan(min):\n",
    "        return np.nan\n",
    "    if (max == min):\n",
    "        return np.nan\n",
    "    \n",
    "    if return_fraction & (max - min < bw):\n",
    "        return 1. # All values are within bw\n",
    "    \n",
    "    # If ALL data are within bw, then it does not make sense to make \n",
    "    # a sliding window. We reduce the window to one half until it becomes \n",
    "    # smaller than the range of x:\n",
    "\n",
    "    while bw > (max - min):\n",
    "        bw *= 0.5\n",
    "\n",
    "    if dx is None:\n",
    "        dx = bw / 100\n",
    "    \n",
    "    nn = int((max - min) // dx + 2)\n",
    "    cts, edges = np.histogram(x[~np.isnan(x)], bins=nn, range=(min-dx, max+dx))\n",
    "    csum = np.cumsum(cts) / np.sum(cts)\n",
    "    nsumbins = int(bw//dx)\n",
    "    running_sum = csum[nsumbins:]-csum[:-nsumbins]\n",
    "    xvalues = 0.5*(edges[nsumbins:]+edges[:-nsumbins])[:-1]\n",
    "\n",
    "    max_running_sum = np.nanmax(running_sum)\n",
    "    if np.isnan(max_running_sum):\n",
    "        return np.nan\n",
    "    \n",
    "    if return_fraction:\n",
    "        return max_running_sum\n",
    "\n",
    "    return xvalues[np.nanargmax(running_sum)]\n",
    "\n",
    "def find_fraction_in_mode(x):\n",
    "    return find_mode(x, bw=0.15, dx=None, return_fraction=True)\n",
    "\n",
    "def find_intensity_mode(x):\n",
    "    return find_mode(x, bw=40) # 40 photoelectrons sliding-window\n",
    "\n",
    "# Average RA, asumed to be in degrees\n",
    "def ra_mean(ra):\n",
    "    cosra = np.cos(ra*u.deg)\n",
    "    sinra = np.sin(ra*u.deg)\n",
    "\n",
    "    meanra = np.arctan2(sinra.mean(), cosra.mean())\n",
    "    if meanra < 0:\n",
    "        meanra += 2*np.pi*u.rad\n",
    "\n",
    "    return meanra.to_value(u.deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76177f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_span = cis['runnumber'].max() - cis['runnumber'].min() + 1\n",
    "runmin = cis['runnumber'].min() - 0.5\n",
    "runmax = cis['runnumber'].max() + 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1132089",
   "metadata": {},
   "source": [
    "## Compute more run-wise quantities, needed to apply the data selection cuts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6083edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonan = ~np.isnan(cis['ZD_corrected_cosmics_rate_at_422_pe'])\n",
    "mean_R422, bin_edges, _ = binned_statistic(cis['runnumber'][nonan], \n",
    "                                           cis['ZD_corrected_cosmics_rate_at_422_pe'][nonan], \n",
    "                                           statistic='mean', bins=run_span, range=(runmin, runmax))\n",
    "std_R422, _, _ = binned_statistic(cis['runnumber'][nonan], \n",
    "                                  cis['ZD_corrected_cosmics_rate_at_422_pe'][nonan], \n",
    "                                  statistic='std', bins=bin_edges)\n",
    "mode_R422, _, _ = binned_statistic(cis['runnumber'][nonan], \n",
    "                                   cis['ZD_corrected_cosmics_rate_at_422_pe'][nonan], \n",
    "                                   statistic=find_mode, bins=bin_edges)\n",
    "fraction_around_mode_R422, _, _ = binned_statistic(cis['runnumber'][nonan], \n",
    "                                                   cis['ZD_corrected_cosmics_rate_at_422_pe'][nonan], \n",
    "                                                   statistic=find_fraction_in_mode, bins=bin_edges)\n",
    "\n",
    "\n",
    "nonan = (cis['intensity_at_reference_rate'] < 1000) # this rempoves nans but also rare rogue values\n",
    "mean_intensity_at_reference_rate, _, _ =  binned_statistic(cis['runnumber'][nonan], \n",
    "                                                           cis['intensity_at_reference_rate'][nonan], \n",
    "                                                           statistic='mean', bins=bin_edges)\n",
    "std_intensity_at_reference_rate, _, _ =  binned_statistic(cis['runnumber'][nonan], \n",
    "                                                          cis['intensity_at_reference_rate'][nonan], \n",
    "                                                          statistic='std', bins=bin_edges)\n",
    "\n",
    "mean_light_yield, _, _ = binned_statistic(cis['runnumber'][nonan], \n",
    "                                          cis['light_yield'][nonan], \n",
    "                                          statistic='mean', bins=run_span, range=(runmin, runmax))\n",
    "std_light_yield, _, _ = binned_statistic(cis['runnumber'][nonan], \n",
    "                                         cis['light_yield'][nonan], \n",
    "                                         statistic='std', bins=run_span, range=(runmin, runmax))\n",
    "\n",
    "nonan = ~np.isnan(cis['ZD_corrected_cosmics_spectral_index'])\n",
    "mean_index, _, _ = binned_statistic(cis['runnumber'][nonan], \n",
    "                                    cis['ZD_corrected_cosmics_spectral_index'][nonan], \n",
    "                                           statistic='mean', bins=run_span, range=(runmin, runmax))\n",
    "std_index, _, _ = binned_statistic(cis['runnumber'][nonan], \n",
    "                                   cis['ZD_corrected_cosmics_spectral_index'][nonan], \n",
    "                                           statistic='std', bins=run_span, range=(runmin, runmax))\n",
    "\n",
    "\n",
    "\n",
    "# Note: the P-value of the (subrun-wise) power-law fits to the intensity spectra is properly distributed \n",
    "# (uniform from 0 to 1) for practically all subruns. Note that the run-averaged P-value no longer has a \n",
    "# uniform distribution! For good runs it is a gaussuan-ish distribution around 0.5 (central limit theorem!)\n",
    "mean_fit_p_value, _, _ =  binned_statistic(cis['runnumber'][nonan], \n",
    "                                           cis['intensity_spectrum_fit_p_value'][nonan], \n",
    "                                           statistic='mean', bins=bin_edges)\n",
    "\n",
    "nonan = ~np.isnan(cis['ZD_corrected_intensity_at_half_peak_rate'])\n",
    "mean_intensity_threshold, _, _ =  binned_statistic(cis['runnumber'][nonan], \n",
    "                                                   cis['ZD_corrected_intensity_at_half_peak_rate'][nonan], \n",
    "                                                   statistic='mean', bins=bin_edges)\n",
    "std_intensity_threshold, _, _ =  binned_statistic(cis['runnumber'][nonan], \n",
    "                                                  cis['ZD_corrected_intensity_at_half_peak_rate'][nonan], \n",
    "                                                  statistic='std', bins=bin_edges)\n",
    "\n",
    "nonan = ~np.isnan(cis['intensity_at_peak_rate'])\n",
    "# NOTE: THE INTENSITIES AT PEAK RATE ARE NOT ZD-CORRECTED! THIS IS BECAUSE WE DO NOT USE IT FOR THE \n",
    "# QUALITY SELECTION, BUT ONLY TO ESTIMATE WHAT INTENSITY CUT MAY BE REASONABLE TO USE IN LATER ANALYSIS!\n",
    "mean_intensity_at_peak_rate, _, _ =  binned_statistic(cis['runnumber'][nonan], \n",
    "                                                      cis['intensity_at_peak_rate'][nonan], \n",
    "                                                      statistic='mean', bins=bin_edges)\n",
    "std_intensity_at_peak_rate, _, _ =  binned_statistic(cis['runnumber'][nonan], \n",
    "                                                  cis['intensity_at_peak_rate'][nonan], \n",
    "                                                  statistic='std', bins=bin_edges)\n",
    "\n",
    "\n",
    "\n",
    "mean_ra, _, _  = binned_statistic(cis['runnumber'], cis['ra_tel'], statistic=ra_mean, bins=bin_edges)\n",
    "mean_dec, _, _ = binned_statistic(cis['runnumber'], cis['dec_tel'], statistic='mean', bins=bin_edges)\n",
    "std_dec, _, _ = binned_statistic(cis['runnumber'], cis['dec_tel'], statistic='std', bins=bin_edges)\n",
    "# We do not compute std_ra - it is not totally straightforward because of 0=360 deg...\n",
    "\n",
    "mean_coszd, _, _ = binned_statistic(cis['runnumber'], cis['cos_zenith'], statistic=ra_mean, bins=bin_edges)\n",
    "\n",
    "nonan = ~np.isnan(cis['diffuse_nsb_std'])\n",
    "mean_diffuse_nsb_std, _ , _ = binned_statistic(cis['runnumber'][nonan], \n",
    "                                               cis['diffuse_nsb_std'][nonan], \n",
    "                                               statistic='mean', bins=bin_edges)\n",
    "\n",
    "\n",
    "nsubruns, _ = np.histogram(cis['runnumber'], bins=bin_edges)\n",
    "run_exists = nsubruns>0\n",
    "\n",
    "# NOTE: some \"All-NaN slice warnings may appear, because of (rare) really bad data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b7ebda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Development NOTE, AM, TBF?\n",
    "#\n",
    "# Applying cuts in mean values through a run (of subrun-wise-computed quantities) somehow \"favours\" long runs. \n",
    "# The spread of the mean values will decrease as 1/sqrt(N_subruns), so all other thing being equal,\n",
    "# a short run has a smaller chance of surviving cuts. Anyway, short runs are often short because of various \n",
    "# issues, so probably this is not a big deal!\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ce2f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just to make sure the same number of subruns are present \n",
    "assert((nsubruns>0).sum() == max_lsc.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527228b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove \"empty entries\" (i.e. removes run numbers which are not in loaded sample,\n",
    "# e.g. because do not correspond to sky runs)\n",
    "\n",
    "mean_R422 = mean_R422[run_exists]\n",
    "std_R422  = std_R422[run_exists]\n",
    "mode_R422 = mode_R422[run_exists]\n",
    "mean_intensity_at_reference_rate = mean_intensity_at_reference_rate[run_exists]\n",
    "std_intensity_at_reference_rate = std_intensity_at_reference_rate[run_exists]\n",
    "fraction_around_mode_R422 = fraction_around_mode_R422[run_exists]\n",
    "mean_light_yield = mean_light_yield[run_exists]\n",
    "std_light_yield = std_light_yield[run_exists]\n",
    "mean_index = mean_index[run_exists]\n",
    "std_index = std_index[run_exists]\n",
    "mean_intensity_threshold = mean_intensity_threshold[run_exists]\n",
    "std_intensity_threshold = std_intensity_threshold[run_exists]\n",
    "mean_intensity_at_peak_rate = mean_intensity_at_peak_rate[run_exists]\n",
    "std_intensity_at_peak_rate = std_intensity_at_peak_rate[run_exists]\n",
    "mean_ra = mean_ra[run_exists]\n",
    "mean_dec = mean_dec[run_exists]\n",
    "std_dec = std_dec[run_exists]\n",
    "mean_coszd = mean_coszd[run_exists]\n",
    "mean_diffuse_nsb_std = mean_diffuse_nsb_std[run_exists]\n",
    "mean_fit_p_value = mean_fit_p_value[run_exists]\n",
    "nsubruns = nsubruns[run_exists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d25d9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define here all the selection masks using the values set by the user above.\n",
    "\n",
    "interleaved_ok_selection = np.array(runlist.size*[True]) \n",
    "\n",
    "if require_interleaved_flatfield:\n",
    "    interleaved_ok_selection &= (runsummary['num_flatfield'] > 0).to_numpy()\n",
    "if require_interleaved_pedestals:\n",
    "    interleaved_ok_selection &= (runsummary['num_pedestals'] > 0).to_numpy()\n",
    "# interleaved_ok means just that some events were identified as interleaved FF and pedestal!\n",
    "    \n",
    "telescope_pointing = SkyCoord(ra=mean_ra*u.deg, dec=mean_dec*u.deg)\n",
    "\n",
    "skyregion_selection = np.array(runlist.size*[True]) # All Sky, if no source selection\n",
    "if source_coordinates != None:\n",
    "    angular_distance = source_coordinates.separation(telescope_pointing)\n",
    "    skyregion_selection = (angular_distance > min_angle_to_source) & (angular_distance < max_angle_to_source)\n",
    "\n",
    "pointing_stability_selection = std_dec < max_pointing_dec_std # Stable pointing\n",
    "    \n",
    "maxcoszd = np.cos(min_zenith)\n",
    "mincoszd = np.cos(max_zenith)\n",
    "# Note that the zenith limit is done with the run's mean, so there will be some events beyond the limits:\n",
    "zd_selection = (mean_coszd > mincoszd) & (mean_coszd < maxcoszd)\n",
    "\n",
    "nsb_selection = mean_diffuse_nsb_std < max_diffuse_nsb_std\n",
    "\n",
    "date_selection = (rundate >= first_date) & (rundate <= last_date)\n",
    "\n",
    "# P-value for good fits is distributed uniformly between 0 and 1 (which has std dev = 1/sqrt(12)). \n",
    "# So the mean of N such quantities is distributed (for N large) approximately as a a gaussian of \n",
    "# mean 0.5 and std dev = 1/sqrt(12*N). The cut below removes runs for which the power-law fits of\n",
    "# the cosmic rays intensity spectra, dR/dI, are (in average) poor:\n",
    "p_value_selection = (mean_fit_p_value-0.5)*(12*nsubruns)**0.5 > min_mean_fit_p\n",
    "\n",
    "LS_periodogram_selection = max_lsc < max_LS_periodogram_maxamplitude\n",
    "\n",
    "drdi_index_selection = (mean_index > min_drdi_index) & (mean_index < max_drdi_index) \n",
    "\n",
    "# the dR/dI rate selection includes a condition on its stability during the run. We require a \n",
    "# minimum fraction \"min_fraction_around_mode\" (defined above) of the subruns to be within +/- 0.075 of \n",
    "# the mode. This is to identify runs with large variations (sometimes due to spurious sources of triggers,\n",
    "# like e.g. car flashes or the MAGIC LIDAR)\n",
    "drdi_rate_selection = (mean_R422 > min_drdi_at_422pe) & (fraction_around_mode_R422 > min_fraction_around_mode)\n",
    "\n",
    "intensity_threshold_selection = mean_intensity_threshold < max_intensity_at_half_peak_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609bcdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 15))\n",
    "\n",
    "\n",
    "fig.add_subplot(5, 2, 1)\n",
    "# Pointing stability\n",
    "cc, bb, _ = plt.hist(std_dec, bins=250, range=(0,0.05), label='All data',\n",
    "                    log=True, color='lightgrey', density=True)\n",
    "plt.hist(std_dec[interleaved_ok_selection & skyregion_selection & date_selection], bins=bb,\n",
    "         label='Runs for selected\\n source & dates',\n",
    "         log=True, density=True, histtype='step')\n",
    "\n",
    "plt.plot([max_pointing_dec_std, max_pointing_dec_std], [0, cc.max()], '--', label='Maximum allowed', \n",
    "         color='red')\n",
    "plt.xlabel('Declination std dev within run (degrees)')\n",
    "plt.ylabel('number of runs (normalized)')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "fig.add_subplot(5, 2, 2)\n",
    "cc, bb, _ = plt.hist(np.rad2deg(np.arccos(mean_coszd)), bins=180, range=(0,90), label='All data',\n",
    "                     color='lightgrey', density=True)\n",
    "\n",
    "plt.hist(np.rad2deg(np.arccos(mean_coszd))[interleaved_ok_selection & skyregion_selection & date_selection], \n",
    "         bins=bb, label='Runs for selected\\n source & dates',\n",
    "         density=True, histtype='step')\n",
    "\n",
    "plt.plot([max_zenith.to_value(u.deg), max_zenith.to_value(u.deg)], \n",
    "         [0, cc.max()], '--', label='Maximum allowed', color='red')\n",
    "plt.plot([min_zenith.to_value(u.deg), min_zenith.to_value(u.deg)], \n",
    "         [0, cc.max()], '--', label='Minimum allowed', color='green')\n",
    "\n",
    "plt.xlabel('Zenith angle (degrees)')\n",
    "plt.ylabel('number of runs (normalized)')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "fig.add_subplot(5, 2, 3)\n",
    "cc, bb, _ = plt.hist(mean_diffuse_nsb_std, bins=200, range=(0,10), label='All data',\n",
    "                     color='lightgrey', density=True)\n",
    "\n",
    "plt.hist(mean_diffuse_nsb_std[interleaved_ok_selection & skyregion_selection & date_selection], bins=bb,\n",
    "         label='Runs for selected\\n source & dates',\n",
    "         density=True, histtype='step')\n",
    "\n",
    "plt.plot([max_diffuse_nsb_std, max_diffuse_nsb_std], \n",
    "         [0, cc.max()], '--', label='Maximum allowed', color='red')\n",
    "plt.xlabel('Diffuse NSB std dev (p.e.)')\n",
    "plt.ylabel('number of runs (normalized)')\n",
    "plt.legend()\n",
    "\n",
    "fig.add_subplot(5, 2, 4)\n",
    "cc, bb, _ = plt.hist((mean_fit_p_value-0.5)*(12*nsubruns)**0.5, \n",
    "                     bins=150, range=(-6,9), label='All data',\n",
    "                     color='lightgrey', density=True)\n",
    "plt.hist(((mean_fit_p_value-0.5)*(12*nsubruns)**0.5)[interleaved_ok_selection & \n",
    "                                                     skyregion_selection & date_selection], \n",
    "         bins=bb, label='Runs for selected\\n source & dates',\n",
    "         density=True, histtype='step')\n",
    "plt.plot([min_mean_fit_p, min_mean_fit_p], \n",
    "         [0, cc.max()], '--', label='Minimum allowed', color='green')\n",
    "plt.xlabel('(mean_dR/dI_fit_P_value-0.5)/sqrt(12*nsubruns)')\n",
    "plt.ylabel('number of runs (normalized)')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "fig.add_subplot(5, 2, 5)\n",
    "cc, bb, _ = plt.hist(mean_R422, bins=200, range=(0,5), label='All data',\n",
    "                     color='lightgrey', density=True)\n",
    "\n",
    "plt.hist(mean_R422[interleaved_ok_selection & skyregion_selection & date_selection], bins=bb,\n",
    "         label='Runs for selected\\n source & dates',\n",
    "         density=True, histtype='step')\n",
    "\n",
    "plt.plot([min_drdi_at_422pe, min_drdi_at_422pe], \n",
    "         [0, cc.max()], '--', label='Minimum allowed', color='green')\n",
    "plt.xlabel('dR/dI cosmics rate at 422 p.e. (evts/s/p.e.)')\n",
    "plt.ylabel('number of runs (normalized)')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "fig.add_subplot(5, 2, 6)\n",
    "cc, bb, _ = plt.hist(fraction_around_mode_R422, bins=200, range=(0,1), \n",
    "                     label='All data', color='lightgrey', density=True)\n",
    "plt.hist(fraction_around_mode_R422[interleaved_ok_selection & skyregion_selection & date_selection], bins=bb,\n",
    "         label='Runs for selected\\n source & dates', density=True, histtype='step')\n",
    "\n",
    "plt.plot([min_fraction_around_mode, min_fraction_around_mode],\n",
    "         [0, cc.max()], '--', label='Minimum allowed', color='green')\n",
    "plt.xlabel('Fraction of dR/dI values around the mode for the run')\n",
    "plt.ylabel('number of runs (normalized)')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "\n",
    "fig.add_subplot(5, 2, 7)\n",
    "cc, bb, _ = plt.hist(mean_index, bins=200, range=(-3,0), label='All data',\n",
    "                     color='lightgrey', density=True)\n",
    "\n",
    "plt.hist(mean_index[interleaved_ok_selection & skyregion_selection & date_selection], bins=bb,\n",
    "         label='Runs for selected\\n source & dates',\n",
    "         density=True, histtype='step')\n",
    "\n",
    "plt.plot([min_drdi_index, min_drdi_index], \n",
    "         [0, cc.max()], '--', label='Minimum allowed', color='green')\n",
    "plt.plot([max_drdi_index, max_drdi_index], \n",
    "         [0, cc.max()], '--', label='Maximum allowed', color='red')\n",
    "plt.xlabel('dR/dI cosmics rate power index at 422 p.e.')\n",
    "plt.ylabel('number of runs (normalized)')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "fig.add_subplot(5, 2, 8)\n",
    "cc, bb, _ = plt.hist(np.log10(max_lsc), bins=100, range=(-6,0), label='All data',\n",
    "                     color='lightgrey', density=True)\n",
    "plt.hist(np.log10(max_lsc)[interleaved_ok_selection & skyregion_selection & date_selection], bins=bb,\n",
    "         label='Runs for selected\\n source & dates',\n",
    "         density=True, histtype='step')\n",
    "plt.plot([np.log10(max_LS_periodogram_maxamplitude), \n",
    "          np.log10(max_LS_periodogram_maxamplitude)], \n",
    "         [0, cc.max()], '--', label='Maximum allowed', color='red')\n",
    "plt.xlabel('Log10(max amplitude in LS periodogram)')\n",
    "plt.ylabel('number of runs (normalized)')\n",
    "plt.legend()\n",
    "\n",
    "fig.add_subplot(5, 2, 9)\n",
    "cc, _, _ = plt.hist(mean_intensity_threshold, \n",
    "                    bins=200, range=(0,200), label='All data',\n",
    "                    density=True, color='lightgrey')\n",
    "\n",
    "cc, _, _ = plt.hist(mean_intensity_threshold[interleaved_ok_selection & skyregion_selection & date_selection], \n",
    "                    bins=200, range=(0,200), label='Runs for selected\\n source & dates',\n",
    "                    density=True, histtype='step')\n",
    "plt.plot([max_intensity_at_half_peak_rate, max_intensity_at_half_peak_rate],\n",
    "         [0, cc.max()], '--', label='Maximum allowed', color='red')\n",
    "\n",
    "plt.grid()\n",
    "plt.xlabel('Intensity at 50% of dR/dI peak rate (mean during run) (p.e.)')\n",
    "plt.ylabel('number of runs (normalized)')\n",
    "plt.legend()\n",
    "\n",
    "fig.add_subplot(5, 2, 10)\n",
    "cc, _, _ = plt.hist(mean_intensity_at_peak_rate, \n",
    "                    bins=200, range=(0,200), label='All data', \n",
    "                    density=True, color='lightgrey')\n",
    "\n",
    "cc, _, _ = plt.hist(mean_intensity_at_peak_rate[interleaved_ok_selection & skyregion_selection & date_selection], \n",
    "                    bins=200, range=(0,200), label='Runs for selected\\n source & dates', # log=True, \n",
    "                    density=True, histtype='step')\n",
    "plt.grid()\n",
    "plt.xlabel('Intensity at dR/dI peak rate (mean during run) (p.e.)')\n",
    "plt.ylabel('number of runs (normalized)')\n",
    "plt.legend()\n",
    "\n",
    "print()\n",
    "print('The dR/dI spectrum parameters below are corrected (for each subrun) to their ZD=0 equivalent')\n",
    "print('except the intensity at the dR/dI peak rate')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f744ad",
   "metadata": {},
   "source": [
    "### In the last row of plots above we show the distribution of the (ZD-corrected) \"intensity threshold\", defined as the position of the rising edge (50% of peak) of the cosmic ray intensity spectrum, and the distribution of the intensity at which the peak is located (the latter is **not** corrected for zenith)\n",
    "\n",
    "Note that the data may be perfectly healthy even when they have a higher threshold than usual. But it is dangerous (systematic-errors-wise) to use events with intensities well below the peak, because of MC-data discrepancies (standard MC is produced such that it resembles \"optimal data\" in terms of threshold).\n",
    "\n",
    "The event-wise cut in intensity that we apply in the higher-level analyis of the low-threshold data (with say, intensity at 50% of peak rate <40 p.e.) is intensity>50 p.e. The cut should be higher (to prevent biases in flux calculations) for data with higher threshold.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a9e9ec",
   "metadata": {},
   "source": [
    "## Print some run selection statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3862e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nNumber of runs (% is w.r.t. those in Sky region & zenith range):\\n')\n",
    "starting_nruns = (date_selection & skyregion_selection).sum()\n",
    "print('    In the requested Sky region and range of dates:\\t', starting_nruns)\n",
    "\n",
    "nruns_within_zdrange = (date_selection & skyregion_selection & zd_selection).sum()\n",
    "print('  + zenith in requested range:\\t\\t\\t\\t', nruns_within_zdrange)\n",
    "\n",
    "nruns_nsb_ok = (date_selection & skyregion_selection & zd_selection &\n",
    "                nsb_selection).sum()\n",
    "print('  + NSB in requested range:\\t\\t\\t\\t', nruns_nsb_ok,\n",
    "      f'({nruns_nsb_ok/nruns_within_zdrange*100:.1f}%)\\n')\n",
    "\n",
    "\n",
    "nruns_interleaved_ok = (date_selection & skyregion_selection & zd_selection &\n",
    "                        nsb_selection & interleaved_ok_selection).sum()\n",
    "print('  + FF and pedestal interleaved events are present:\\t', nruns_interleaved_ok,\n",
    "      f'({nruns_interleaved_ok/nruns_within_zdrange*100:.1f}%)')\n",
    "\n",
    "nruns_stable_pointing = (date_selection & skyregion_selection & zd_selection &\n",
    "                         nsb_selection & interleaved_ok_selection & \n",
    "                         pointing_stability_selection).sum()\n",
    "print('  + Stable pointing:\\t\\t\\t\\t\\t', nruns_stable_pointing,\n",
    "      f'({nruns_stable_pointing/nruns_within_zdrange*100:.1f}%)')\n",
    "\n",
    "nruns_fit_p_value_ok = (date_selection & skyregion_selection & zd_selection &\n",
    "                        nsb_selection & interleaved_ok_selection & \n",
    "                        pointing_stability_selection &\n",
    "                        p_value_selection).sum()\n",
    "print('  + dR/dI fit P-value ok:\\t\\t\\t\\t', nruns_fit_p_value_ok,\n",
    "      f'({nruns_fit_p_value_ok/nruns_within_zdrange*100:.1f}%)')\n",
    "\n",
    "nruns_LS_periodogram_ok = (date_selection & skyregion_selection & zd_selection &\n",
    "                           nsb_selection & interleaved_ok_selection & \n",
    "                           pointing_stability_selection &\n",
    "                           p_value_selection & LS_periodogram_selection).sum()\n",
    "print('  + dR/dI LS periodogram ok:\\t\\t\\t\\t', nruns_LS_periodogram_ok,\n",
    "      f'({nruns_LS_periodogram_ok/nruns_within_zdrange*100:.1f}%)')\n",
    "\n",
    "nruns_drdi_index_ok = (date_selection & skyregion_selection & zd_selection &\n",
    "                       nsb_selection & interleaved_ok_selection & \n",
    "                       pointing_stability_selection & \n",
    "                       p_value_selection & LS_periodogram_selection &\n",
    "                       drdi_index_selection).sum()\n",
    "print('  + dR/dI index ok:\\t\\t\\t\\t\\t', nruns_drdi_index_ok,\n",
    "      f'({nruns_drdi_index_ok/nruns_within_zdrange*100:.1f}%)')\n",
    "\n",
    "nruns_drdi_rate_ok = (date_selection & skyregion_selection & zd_selection &\n",
    "                      nsb_selection & interleaved_ok_selection & \n",
    "                      pointing_stability_selection & \n",
    "                      p_value_selection & LS_periodogram_selection &\n",
    "                      drdi_index_selection & drdi_rate_selection).sum()\n",
    "\n",
    "print('  + dR/dI rate ok:\\t\\t\\t\\t\\t', nruns_drdi_rate_ok,\n",
    "      f'({nruns_drdi_rate_ok/nruns_within_zdrange*100:.1f}%)')\n",
    "\n",
    "nruns_threshold_ok = (date_selection & skyregion_selection & zd_selection &\n",
    "                      nsb_selection & interleaved_ok_selection & \n",
    "                      pointing_stability_selection & \n",
    "                      p_value_selection & LS_periodogram_selection &\n",
    "                      drdi_index_selection & drdi_rate_selection &\n",
    "                      intensity_threshold_selection).sum()\n",
    "\n",
    "print('  + intensity threshold ok:\\t\\t\\t\\t', nruns_threshold_ok,\n",
    "      f'({nruns_drdi_rate_ok/nruns_within_zdrange*100:.1f}%)')\n",
    "\n",
    "print('\\nNote: about 64% of all *dark-night* observations within ZD<80 deg fulfill all quality cuts.')\n",
    "print('(in the stable, good-quality period 20221118 - 20230214, 92% of *dark-night* observations within ZD<80 deg do).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcd283b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All selections but the dR/dI rate cuts:\n",
    "mask_no_drdi_rate_cut = (date_selection & \n",
    "                         skyregion_selection & \n",
    "                         zd_selection & \n",
    "                         nsb_selection &\n",
    "                         interleaved_ok_selection & \n",
    "                         pointing_stability_selection & \n",
    "                         p_value_selection &\n",
    "                         LS_periodogram_selection &\n",
    "                         drdi_index_selection &\n",
    "                         intensity_threshold_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8662b3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = mask_no_drdi_rate_cut & drdi_rate_selection\n",
    "\n",
    "good_runs = runlist[mask]\n",
    "\n",
    "print('Selected:', mask.sum(), 'of', runlist.size, 'runs')\n",
    "\n",
    "obs_hours = runsummary['elapsed_time'][mask].sum()/3600\n",
    "\n",
    "print(f'Total observation time: {obs_hours:.2f} h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8e5a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a mask of selected data which works for the subrun-wise table:\n",
    "subrun_mask = np.array([True if x in good_runs else False for x in cis['runnumber']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8daba83b",
   "metadata": {},
   "source": [
    "### Now we obtain, from the (run-wise) diffuse NSB std values, the median, and identify a few \"typical\" subruns that we can then use to find (using the script lstchain_tune_nsb) the parameters needed to tune the MC (in the DL1ab step) for later analysis\n",
    "\n",
    "Note that the NSB tuning (also called \"noise padding\") of the MC at the DL1ab analysis step (which starts with already integrated waveforms for each pixel, using a peak-search algorithm) will not work for an NSB level much higher than the one in the MC. The reason is that in such a case the peak search algorithm would often pick a random NSB fluctuation instead of the actual Cherenkov pulse, hence just adding noise to the original integrated value is not a proper way to reproduce the effect in the data.\n",
    "\n",
    "As a rule of thumb:\n",
    "* if the median NSB standard deviation in the sample (reported below) **below 1.6 p.e.** you can use the **standard MC** without tuning.\n",
    "* if it is **between 1.6 and 4 p.e.**, you can use the simple NSB tuning approach of the MC at the DL1ab level (see documentation of the script **lstchain_tune_nsb**)\n",
    "* for values **above 4 p.e.** it is better to tune the MC at the R0 to DL1 step, by adding random noise to the waveforms (i.e. before pulse integration). This has to be done using the **\"waveform_nsb_tuning\"** option in the lstchain*.json configuration file when running the R0 to DL1 step for the MC. See the script **lstchain_tune_nsb_waveform**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b32776",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsb_median = np.median(mean_diffuse_nsb_std[mask])\n",
    "\n",
    "print(f'\\nMedian of the NSB standard deviation for the sample: {nsb_median:.3f} p.e.')\n",
    "if nsb_median < 1.6:\n",
    "    print('This sample can probable be analyzed properly using the standard Monte Carlo.')\n",
    "elif nsb_median < 4:\n",
    "    print('It is recommended to use NSB-tuned MC (using lstchain_tune_nsb and lstchain_dl1ab) for analyzing this sample.')\n",
    "else:\n",
    "    print('It is recommended to use MC with matching NSB (using the waveform_nsb_tuning option in the MC R0 to DL1 step).')\n",
    "\n",
    "print('\\nSubruns with NSB std dev closest to sample median:\\n')\n",
    "\n",
    "dnsb = cis['diffuse_nsb_std'].to_numpy()\n",
    "nonan = np.isfinite(dnsb)\n",
    "eltime = cis['elapsed_time'].to_numpy() \n",
    "goodtime = eltime > np.nanmedian(eltime) # Just to avoid too short subruns (e.g. at the endf of a run)\n",
    "\n",
    "argsrt = np.argsort(np.abs(dnsb[subrun_mask & nonan & goodtime] - nsb_median))\n",
    "\n",
    "for iarg in argsrt[:5]:\n",
    "    ymd = cis['yyyymmdd'][subrun_mask & nonan & goodtime].to_numpy()[iarg]\n",
    "    rn = cis['runnumber'][subrun_mask & nonan & goodtime].to_numpy()[iarg]\n",
    "    srn = cis['subrun'][subrun_mask & nonan & goodtime].to_numpy()[iarg]\n",
    "    print(f'{ymd}   Run{rn:05d}.{srn:04d}   NSB std dev: {dnsb[subrun_mask & nonan & goodtime][iarg]:.3f} p.e.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41884dfd",
   "metadata": {},
   "source": [
    "## Plot the evolution of dR/dI and the \"light yield\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e78cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 3.5))\n",
    "plt.scatter(runlist, mean_R422, s=2, color='lightgrey', label='All data')\n",
    "plt.scatter(runlist[mask], mean_R422[mask], s=2, label='Selected runs')\n",
    "\n",
    "plt.scatter(runlist[(~mask) & mask_no_drdi_rate_cut], mean_R422[(~mask) & mask_no_drdi_rate_cut], s=2, \n",
    "            label='Runs which failed dR/dI rate selection')\n",
    "\n",
    "plt.xlabel('Run number')\n",
    "plt.ylabel('dR/dI cosmics rate at 422 p.e. (evts/s/p.e.)')\n",
    "plt.ylim(0, 4.5)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f306f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# If you need to produce a plot vs. the actual date, and not run number, here is an example:\n",
    "# (Uncomment code below to test)\n",
    "#\n",
    "\n",
    "# runtime = np.array([runsummary['time'][runsummary['runnumber']==rr].array[0] for rr in runlist])\n",
    "\n",
    "# from datetime import datetime\n",
    "# utctime = [datetime.utcfromtimestamp(x) for x in runtime]\n",
    "# plt.figure(figsize=(12, 3.5))\n",
    "# plt.scatter(utctime, mean_R422, s=2, color='lightgrey', label='All data')\n",
    "\n",
    "# utctime = [datetime.utcfromtimestamp(x) for x in runtime[mask]]\n",
    "# plt.scatter(utctime, mean_R422[mask], s=2, label='Selected runs')\n",
    "\n",
    "\n",
    "# utctime = [datetime.utcfromtimestamp(x) for x in runtime[(~mask) & mask_no_drdi_rate_cut]]\n",
    "# plt.scatter(utctime, mean_R422[(~mask) & mask_no_drdi_rate_cut], s=2, \n",
    "#             label='Runs which failed dR/dI rate selection')\n",
    "\n",
    "# plt.ylabel('dR/dI cosmics rate at 422 p.e. (evts/s/p.e.)')\n",
    "# plt.ylim(0, 4.5)\n",
    "# plt.legend()\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88751c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 3.5))\n",
    "plt.scatter(runlist, mean_light_yield, s=2, color='lightgrey', label='All data')\n",
    "plt.scatter(runlist[mask], mean_light_yield[mask], s=2, label='Selected runs')\n",
    "\n",
    "plt.scatter(runlist[(~mask) & mask_no_drdi_rate_cut], mean_light_yield[(~mask) & mask_no_drdi_rate_cut], s=2, \n",
    "            label='Runs which failed dR/dI rate selection')\n",
    "\n",
    "plt.xlabel('Run number')\n",
    "plt.ylabel('Relative light yield')\n",
    "plt.ylim(0, 2)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5cb63f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Show for (at most) 10 of the selected spectra the evolution of dR/dI through the run:\n",
    "step = 1\n",
    "if mask.sum() > 10:\n",
    "    step = int(mask.sum()//10)\n",
    "\n",
    "for jj in runlist[mask][::step]:\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    print('Run:', jj) \n",
    "    print(f'    Run-averaged dR/dI @ 422 p.e. = {mean_R422[runlist==jj][0]:.3f}')\n",
    "    print(f'    Fraction of subruns around dR/dI mode = {fraction_around_mode_R422[runlist==jj][0]:.3f}'\n",
    "          f' (minimum allowed: {min_fraction_around_mode})')\n",
    "    print(f'    max_lsc: {max_lsc[runlist==jj][0]:.2e}')\n",
    "\n",
    "    xt = cis['time'][cis['runnumber']==jj] - cis['time'][cis['runnumber']==jj].min()\n",
    "    plt.plot(xt,\n",
    "             cis['ZD_corrected_cosmics_rate_at_422_pe'][cis['runnumber']==jj], \n",
    "             label='dR/dI @ 422 p.e.')\n",
    "\n",
    "    plt.plot([xt.min(), xt.max()], [min_drdi_at_422pe, min_drdi_at_422pe], linestyle='--', \n",
    "             linewidth=1, color='tab:blue', label='Minimum allowed run average')\n",
    "    \n",
    "    plt.plot(xt,\n",
    "             -cis['ZD_corrected_cosmics_spectral_index'][cis['runnumber']==jj], \n",
    "             label='dR/dI abs(PL index) @ 422 p.e.')\n",
    "\n",
    "#     plt.scatter(xt,\n",
    "#                 cis['intensity_spectrum_fit_p_value'][cis['runnumber']==jj], \n",
    "#                 label='Fit P-value', color='tab:orange')\n",
    "    plt.grid()\n",
    "\n",
    "    plt.ylim(0, 3)\n",
    "    plt.xlabel('time (s)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d31aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 3))\n",
    "\n",
    "# count number of dR/dI-wise \"anomalous\" subruns in selected sample:\n",
    "drdi_high = 2\n",
    "too_high = 0\n",
    "drdi_low = 1.4\n",
    "too_low = 0\n",
    "total_nsubruns = 0\n",
    "\n",
    "for jj in runlist[mask]:\n",
    "    xt = cis['time'][cis['runnumber']==jj] - cis['time'][cis['runnumber']==jj].min()\n",
    "    plt.plot(xt,\n",
    "             cis['ZD_corrected_cosmics_rate_at_422_pe'][cis['runnumber']==jj])\n",
    "    too_high += (cis['ZD_corrected_cosmics_rate_at_422_pe'][cis['runnumber']==jj] > drdi_high).sum()\n",
    "    too_low  += (cis['ZD_corrected_cosmics_rate_at_422_pe'][cis['runnumber']==jj] < drdi_low).sum()\n",
    "    total_nsubruns += (cis['runnumber']==jj).sum()\n",
    "\n",
    "plt.ylim(0, 3)\n",
    "#plt.xlim(0,1200)\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('dR/dI at 422 p.e.')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "print('Total number of subruns in selected sample:', total_nsubruns)\n",
    "print('Do not panic about the ugly-looking spikes, they are rare:')\n",
    "print(too_high, f'subruns ({100*too_high/total_nsubruns:.3f}%)',' have dR/dI @ 422 larger than', drdi_high)\n",
    "print(too_low,  f'subruns ({100*too_low/total_nsubruns:.3f}%)', ' have dR/dI @ 422 smaller than', drdi_low)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f746b84",
   "metadata": {},
   "source": [
    "## Now we test the stability of the dR/dI - related parameters\n",
    "Note that the gaussian fits attempted below on the selected data (both for the dR/dI values, the corresponding intensities at a reference rate, and the derived \"light yield\") are not necessarily good. Even after the selection you may have periods with different performance, which result in non-gaussian distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dfbd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.distributions import norm\n",
    "from scipy.optimize import curve_fit\n",
    "def gaus(x, a, b, c):\n",
    "    return a*norm.pdf(x, b, c)\n",
    "\n",
    "fig = plt.figure(figsize=(12,4))\n",
    "fig.add_subplot(1, 2, 1)\n",
    "cc, bb = np.histogram(cis['ZD_corrected_cosmics_rate_at_422_pe'][subrun_mask], bins=200, range=(0.5, 2.5))\n",
    "xx = 0.5*(bb[1:]+bb[:-1])\n",
    "plt.errorbar(xx, cc, yerr=cc**0.5, fmt='o', markersize=1)\n",
    "\n",
    "min_content_for_fit = cc.max()/10 # to fit the central part of the distributions\n",
    "\n",
    "# NOTE: you may have to play with starting parameters if fit does not converge:\n",
    "params, _ = curve_fit(gaus, xx[cc>min_content_for_fit], cc[cc>min_content_for_fit], \n",
    "                      sigma=cc[cc>min_content_for_fit]**0.5, \n",
    "                      p0=[100, 1.7, 0.1])\n",
    "print(params)\n",
    "plt.plot(xx, gaus(xx, params[0], params[1], params[2]), linewidth=1,\n",
    "         label=f'mean: {params[1]:.4f}, std: {params[2]:.4f}\\n Relative std dev: {params[2]/params[1]:.4f}')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('dR/dI at 422 p.e.')\n",
    "plt.ylabel('number of subruns')\n",
    "plt.grid()\n",
    "\n",
    "fig.add_subplot(1, 2, 2)\n",
    "cc, bb = np.histogram(cis['intensity_at_reference_rate'][subrun_mask], bins=200, range=(350, 550))\n",
    "xx = 0.5*(bb[1:]+bb[:-1])\n",
    "plt.errorbar(xx, cc, yerr=cc**0.5, fmt='o', markersize=1)\n",
    "\n",
    "# NOTE: you may have to play with starting parameters if fit does not converge:\n",
    "params, _ = curve_fit(gaus, xx[cc>min_content_for_fit], cc[cc>min_content_for_fit], \n",
    "                      sigma=cc[cc>min_content_for_fit]**0.5, \n",
    "                      p0=[100, np.nanmedian(cis['intensity_at_reference_rate'][subrun_mask]), 2])\n",
    "\n",
    "plt.plot(xx, gaus(xx, params[0], params[1], params[2]), linewidth=1,\n",
    "         label=f'mean: {params[1]:.4f}, std: {params[2]:.4f}\\n Relative std dev: {params[2]/params[1]:.4f}')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Intensity at reference rate (p.e.)')\n",
    "plt.ylabel('number of subruns')\n",
    "plt.grid()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44802fd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# cc, bb = np.histogram(((cis['intensity_at_reference_rate']/422)**\n",
    "#                        (cis['ZD_corrected_cosmics_spectral_index']/\n",
    "#                         (1+cis['ZD_corrected_cosmics_spectral_index'])))[subrun_mask], \n",
    "#                       bins=200, range=(0.7, 1.3))\n",
    "\n",
    "cc, bb = np.histogram(cis['light_yield'][subrun_mask], \n",
    "                      bins=200, range=(0.7, 1.3))\n",
    "\n",
    "xx = 0.5*(bb[1:]+bb[:-1])\n",
    "plt.errorbar(xx, cc, yerr=cc**0.5, fmt='o', markersize=1)\n",
    "\n",
    "# NOTE: you may have to play with starting parameters if fit does not converge:\n",
    "params, _ = curve_fit(gaus, xx[cc>min_content_for_fit], cc[cc>min_content_for_fit], \n",
    "                      sigma=cc[cc>min_content_for_fit]**0.5, \n",
    "                       p0=[100, 0, 1])\n",
    "\n",
    "plt.plot(xx, gaus(xx, params[0], params[1], params[2]), linewidth=1,\n",
    "         label=f'mean: {params[1]:.4f}\\nstd: {params[2]:.4f}')\n",
    "         #label=f'mean: {params[1]:.4f}, std: {params[2]:.4f}\\n Relative std dev: {params[2]/params[1]:.4f}')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Relative light yield')\n",
    "plt.ylabel('number of subruns')\n",
    "plt.grid()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22537c6",
   "metadata": {},
   "source": [
    "If we interpret variations in \"Relative light yield\" as variations in atmospheric transmissivity (folded with whatever other factors determining the total amount of collected light, e.g. the telescope throughput), the  std dev of the fit above gives us an idea of the stability of the light measurement throughout the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806cb3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "checklist = runlist[(~mask) & mask_no_drdi_rate_cut]\n",
    "subrun_mask_lowdrdi = np.array([True if x in checklist else False for x in cis['runnumber']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c61b740",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "plt.scatter([], [], facecolors='none', edgecolors='grey', \n",
    "            label='subruns in runs rejected by the dR/dI selections', s=10)\n",
    "plt.scatter([], [], color='black', \n",
    "            label='subruns in selected runs (same color within a run)', s=8)\n",
    "\n",
    "for jj in runlist[mask_no_drdi_rate_cut]:\n",
    "    plt.scatter(cis['cosmics_rate'][cis['runnumber']==jj],\n",
    "                cis['ZD_corrected_cosmics_rate_at_422_pe'][cis['runnumber']==jj], s=8, \n",
    "                facecolors='none', edgecolors='grey', linewidth=0.2)\n",
    "\n",
    "for jj in runlist[mask]:\n",
    "    plt.scatter(cis['cosmics_rate'][cis['runnumber']==jj],\n",
    "                cis['ZD_corrected_cosmics_rate_at_422_pe'][cis['runnumber']==jj], s=2)\n",
    "plt.ylim(0, 3)\n",
    "plt.legend()\n",
    "plt.xlabel('Cosmics trigger rate')\n",
    "plt.ylabel('dR/dI at 422 p.e. (events/s/p.e.)')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74301708",
   "metadata": {},
   "source": [
    "In the plot above:\n",
    "* Subruns with large cosmics trigger rate and low dR/dI values are usually those affected by car flashes or other external sources of light\n",
    "* Low trigger rate and low value of dR/dI likely indicate poor atmospheric transmissivity.\n",
    "* Low trigger rate and \"nominal\" dR/dI are simply runs taken with higher threshold (e.g. moon settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7abe5b",
   "metadata": {},
   "source": [
    "## The cell below can be used to plot a specific run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c688496c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot a specific run, to check the evolution of its dR/dI parameters\n",
    "# This may help identify e.g. if there was a spike in rates, which explains a too high value of the average \n",
    "# cosmics rate dR/dI @ 422 p.e.\n",
    "#\n",
    "# Run number:\n",
    "rr = runlist[0]\n",
    "# 11125 example of a good (=selected) run\n",
    "# 10882 example of many rate spikes\n",
    "# Comment in runbook: \n",
    "# \"busy spike. Operator Specialist cannot reach the toilet without flashing the camera.\"\n",
    "\n",
    "print('Run', rr, 'Date:', rundate[runlist==rr])\n",
    "xt = cis['time'][cis['runnumber']==rr] - cis['time'][cis['runnumber']==rr].min()\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "yy = cis['cosmics_rate'][cis['runnumber']==rr]\n",
    "plt.plot(xt, yy)\n",
    "plt.ylim(yy.min()*0.5, yy.max()*1.2)\n",
    "plt.xlabel('Seconds since start of run')\n",
    "plt.ylabel('Cosmics trigger rate')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "yy = cis['ZD_corrected_cosmics_rate_at_422_pe'][cis['runnumber']==rr]\n",
    "eyy = cis['ZD_corrected_delta_cosmics_rate_at_422_pe'][cis['runnumber']==rr]\n",
    "plt.errorbar(xt, yy, yerr=eyy, fmt='o', markersize=2)\n",
    "plt.plot([xt.min(), xt.max()], [min_drdi_at_422pe, min_drdi_at_422pe], linestyle='--', \n",
    "         linewidth=1, color='tab:blue', label='Minimum allowed run average')\n",
    "plt.legend()\n",
    "plt.ylim(yy.min()*0.5, yy.max()*1.2)\n",
    "plt.xlabel('Seconds since start of run')\n",
    "plt.ylabel('(ZD-corrected) dR/dI at 422 p.e.')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 3.5))\n",
    "yy = cis['ZD_corrected_cosmics_spectral_index'][cis['runnumber']==rr]\n",
    "eyy = cis['delta_cosmics_spectral_index'][cis['runnumber']==rr]\n",
    "plt.errorbar(xt, yy, yerr=eyy, fmt='o', markersize=2)\n",
    "plt.ylim(yy.min()-1, yy.max()+1)\n",
    "plt.xlabel('Seconds since start of run')\n",
    "plt.ylabel('(ZD-corrected) dR/dI pwl index at 422 p.e.')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# We also plot the mean charge in interleaved flatfield events, this helps to see if there is\n",
    "# any problem with the calibration (for example due to a change of HV). Such a problem would \n",
    "# show up as a variation in the calibration charge - which is otherwise expected to be steady\n",
    "plt.figure(figsize=(12, 3))\n",
    "plt.plot(flatfield['subrun'][flatfield['runnumber']==rr], \n",
    "         flatfield['charge_mean'][flatfield['runnumber']==rr])\n",
    "plt.xlabel('Seconds since start of run')\n",
    "plt.ylabel('Mean flatfield charge (p.e.)')\n",
    "plt.grid()\n",
    "plt.ylim(0, 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f45a30",
   "metadata": {},
   "source": [
    "## Function to check whether a given run fulfills all selections (and if not, which ones):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39bd5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_dict = {\"date_selection\": date_selection,\n",
    "             \"skyregion_selection\": skyregion_selection,\n",
    "             \"zd_selection\": zd_selection,\n",
    "             \"nsb_selection\": nsb_selection,\n",
    "             \"interleaved_ok_selection\": interleaved_ok_selection,\n",
    "             \"pointing_stability_selection\": pointing_stability_selection,\n",
    "             \"p_value_selection\": p_value_selection,\n",
    "             \"LS_periodogram_selection\": LS_periodogram_selection,\n",
    "             \"drdi_index_selection\": drdi_index_selection,\n",
    "             \"intensity_threshold_selection\": intensity_threshold_selection,\n",
    "             \"drdi_rate_selection\": drdi_rate_selection}\n",
    "\n",
    "def test_run(run, mask_dict=mask_dict):\n",
    "    if run not in runlist:\n",
    "        print('Run', run, 'is not known. Perhaps it is not a sky run?')\n",
    "        return\n",
    "    if run in good_runs:\n",
    "        print('Run', run, 'passes al selections!')\n",
    "        return\n",
    "    \n",
    "    print('Run', run)\n",
    "    for x in mask_dict:\n",
    "        if mask_dict[x][runlist==run][0]:\n",
    "            continue\n",
    "        print('   ', x, mask_dict[x][runlist==run])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7afe9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: test the first run that did not pass selections\n",
    "for rr in runlist:\n",
    "    if rr not in good_runs:\n",
    "        break\n",
    "\n",
    "test_run(rr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbd2efc",
   "metadata": {},
   "source": [
    "## Check a few of the runs that were REJECTED because of the dR/dI cuts\n",
    "\n",
    "Note: if the only issue (aside from the occasional spike) in a data run is a low mean value of the dR/dI rate at 422 p.e., and/or unstable value (smaller than required fraction of subruns around the mode), then it may be a good candidate for re-analysis via correction of the pixel-wise light values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c66ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs which fulfill all selections except the dR/dI rate selection\n",
    "checklist = runlist[(~mask) & mask_no_drdi_rate_cut]\n",
    "\n",
    "\n",
    "# You can also check runs that fulfill any other condition on the run-wise-averaged quantities we have \n",
    "# computed, for example:\n",
    "# checklist = runlist[max_lsc>1e-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f806fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "checklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bbf5bc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "step = 1\n",
    "if checklist.size > 10:\n",
    "    step = int(checklist.size//10)\n",
    "\n",
    "for jj in checklist[::step]:\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    test_run(jj)\n",
    "    print(f'    Run-averaged dR/dI @ 422 p.e. = {mean_R422[runlist==jj][0]:.3f}')\n",
    "    print(f'    Fraction of subruns around dR/dI mode = {fraction_around_mode_R422[runlist==jj][0]:.3f}'\n",
    "          f' (minimum allowed: {min_fraction_around_mode})')\n",
    "    print(f'    max_lsc: {max_lsc[runlist==jj][0]:.2e}')\n",
    "    \n",
    "    xt = cis['time'][cis['runnumber']==jj] - cis['time'][cis['runnumber']==jj].min()\n",
    "    plt.plot(xt,\n",
    "             cis['ZD_corrected_cosmics_rate_at_422_pe'][cis['runnumber']==jj], label='dR/dI @ 422 p.e.')\n",
    "    plt.plot([xt.min(), xt.max()], [min_drdi_at_422pe, min_drdi_at_422pe], linestyle='--', \n",
    "             linewidth=1, color='tab:blue', label='Minimum allowed run average')\n",
    "\n",
    "\n",
    "    plt.plot(xt,\n",
    "             -cis['ZD_corrected_cosmics_spectral_index'][cis['runnumber']==jj], label='dR/dI abs(PL index) @ 422 p.e.')\n",
    "\n",
    "    plt.grid()\n",
    "\n",
    "    plt.ylim(0, 3)\n",
    "    plt.xlabel('time (s)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd804a2",
   "metadata": {},
   "source": [
    "## Final list of SELECTED runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fb0a71",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "good_dates = np.unique(rundate[mask])\n",
    "\n",
    "print()\n",
    "print('Total number of runs:', good_runs.size, '(in', good_dates.size ,'nights)')\n",
    "obs_hours = runsummary['elapsed_time'][mask].sum()/3600\n",
    "print(f'Total observation time: {obs_hours:.2f} hours')\n",
    "print()\n",
    "\n",
    "for dd in good_dates:\n",
    "    print(dd)\n",
    "    print('--------')\n",
    "    print('  ', runlist[mask & (rundate==dd)])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6707942c",
   "metadata": {},
   "source": [
    "## List of SELECTED run-wise (i.e., merged) DL1 files\n",
    "We look into the directories listed in dl1_dirlist, if file is not found in the first one, we default to the second (currently this means use v0.10 if available, else use v0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a210ad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# dl1_dirlist contains the list of preferred DL1 directories (in order of preference)\n",
    "# Defined at the beginning.\n",
    "\n",
    "if dl1_dirlist is not None:\n",
    "    for rr in good_runs:\n",
    "        dd = rundate[runlist==rr][0]\n",
    "        for ii, dl in enumerate(dl1_dirlist):\n",
    "            dir = dl.replace('YYYYMMDD', str(dd))\n",
    "            filename = dir+f'/dl1*Run{rr:05d}.h5'\n",
    "            ff = glob.glob(filename)\n",
    "            if len(ff) > 0:\n",
    "                print(ff[0])\n",
    "                break\n",
    "            if ii == len(dl1_dirlist) - 1:\n",
    "                print('Warning: file', filename, 'not found')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c0a19b",
   "metadata": {},
   "source": [
    "## List of REJECTED runs that pass all selections **except** the dR/dI rate selection:\n",
    "Those may be good candidates for data correction (e.g. via scaling the light in pixels before the cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6469bdf-98a0-4659-b78c-c6e958a6d4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment lines below to get the list (not done by default because the user might be misled into thinking\n",
    "# those are the good runs)\n",
    "#\n",
    "# not_so_bad_dates = np.unique(rundate[(~mask) & mask_no_drdi_rate_cut])\n",
    "# not_so_bad_obs_hours = runsummary['elapsed_time'][(~mask) & mask_no_drdi_rate_cut].sum()/3600\n",
    "# print()\n",
    "# print(f'Observation time: {not_so_bad_obs_hours:.2f} hours')\n",
    "# print()\n",
    "# for dd in not_so_bad_dates:\n",
    "#     print(dd)\n",
    "#     print('--------')\n",
    "#     print('  ', runlist[(~mask) & mask_no_drdi_rate_cut & (rundate==dd)])\n",
    "#     print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29585dc-830a-4fdd-bef7-86117ccef2c7",
   "metadata": {},
   "source": [
    "## End of the list of REJECTED runs that pass all selections **except** the dR/dI rate selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab483f4f-7bb8-47d6-8c75-23102e271005",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
