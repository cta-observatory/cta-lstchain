{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example to use the custom Container for mono reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from lstchain.io.lstcontainers import DL1ParametersContainer\n",
    "from utils.gammalearn import load_model, load_camera_parameters\n",
    "\n",
    "from ctapipe.utils import get_dataset_path\n",
    "from ctapipe.io import HDF5TableWriter, HDF5TableReader\n",
    "from ctapipe.calib import CameraCalibrator\n",
    "from ctapipe.io import event_source\n",
    "\n",
    "from astropy import units\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = get_dataset_path('gamma_test_large.simtel.gz')   \n",
    "\n",
    "dl1_parameters_filename = 'dl1.h5'\n",
    "\n",
    "allowed_tels = {1} # select LST1 only\n",
    "max_events = 300 # limit the number of events to analyse in files - None if no limit\n",
    "\n",
    "cal = CameraCalibrator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile('lst_bootcamp_gl_data.tar.gz'):\n",
    "    !wget https://gitlab.lapp.in2p3.fr/GammaLearn/GammaLearn/raw/master/share/lst_bootcamp_gl_data.tar.gz\n",
    "    !tar xvzf lst_bootcamp_gl_data.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps_path = 'lst_bootcamp_gl_data/'\n",
    "camera_parameters_path = exps_path + 'camera_parameters.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = 'regression'\n",
    "regression_network = load_model(exps_path, exp_name, 100, camera_parameters_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = 'classification'\n",
    "classification_network = load_model(exps_path, exp_name, 60, camera_parameters_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R0 to DL2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl1_container = DL1ParametersContainer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with HDF5TableWriter(filename=dl1_parameters_filename, group_name='events', overwrite=True) as writer:\n",
    "\n",
    "    source = event_source(infile)\n",
    "    source.allowed_tels = allowed_tels\n",
    "    source.max_events = max_events\n",
    "\n",
    "    for i, event in enumerate(source):\n",
    "        if i%100==0:\n",
    "            print(i)\n",
    "        cal(event)\n",
    "\n",
    "        for telescope_id, dl1 in event.dl1.tel.items():\n",
    "            tel = event.inst.subarray.tels[telescope_id]\n",
    "            camera = tel.camera\n",
    "\n",
    "            image = dl1.image[0]\n",
    "            peakpos = dl1.peakpos[0]\n",
    "\n",
    "            data = torch.tensor([image, peakpos], dtype=torch.float).unsqueeze(0)\n",
    "            prediction = regression_network(data).squeeze(0).detach().numpy()\n",
    "            particle_prediction = classification_network(data)\n",
    "            particle = torch.max(particle_prediction, 1)[1]\n",
    "\n",
    "            ## Fill container ##\n",
    "            dl1_container.fill_mc(event)\n",
    "            dl1_container.fill_event_info(event)\n",
    "            dl1_container.set_mc_core_distance(event, telescope_id)\n",
    "            dl1_container.set_source_camera_position(event, telescope_id)\n",
    "            \n",
    "            event.dl2.energy['gl'].energy = 10**prediction[0] * units.TeV\n",
    "            event.dl2.shower['gl'].core_x = prediction[1] * units.km\n",
    "            event.dl2.shower['gl'].core_y = prediction[2] * units.km\n",
    "            event.dl2.shower['gl'].alt = prediction[3] * units.rad\n",
    "            event.dl2.shower['gl'].az = prediction[4] * units.rad\n",
    "            event.dl2.classification['gl'].prediction = particle.item()\n",
    "\n",
    "            ## Save parameters for later training ##\n",
    "            writer.write(camera.cam_id, [dl1_container, event.dl2.energy['gl'], event.dl2.shower['gl'],\n",
    "                                        event.dl2.classification['gl']])\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The file has been created\n",
    "!ls -lsh dl1.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading hdf5 file is very easy with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_hdf(dl1_parameters_filename, key='events/LSTCam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
