{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "# Example to use the custom Container for mono reconstruction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from lstchain.io.lstcontainers import DL1ParametersContainer\n",
        "from utils.gammalearn import load_model, load_camera_parameters\n",
        "\n",
        "from ctapipe.utils import get_dataset_path\n",
        "from ctapipe.io import HDF5TableWriter, HDF5TableReader\n",
        "from ctapipe.calib import CameraCalibrator\n",
        "from ctapipe.io import event_source\n",
        "\n",
        "from astropy import units\n",
        "\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Options"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "infile \u003d get_dataset_path(\u0027gamma_test_large.simtel.gz\u0027)   \n",
        "\n",
        "dl1_parameters_filename \u003d \u0027dl1.h5\u0027\n",
        "\n",
        "allowed_tels \u003d {1} # select LST1 only\n",
        "max_events \u003d 300 # limit the number of events to analyse in files - None if no limit\n",
        "\n",
        "cal \u003d CameraCalibrator()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Load the model data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "if not os.path.isfile(\u0027lst_bootcamp_gl_data.tar.gz\u0027):\n",
        "    !wget https://gitlab.lapp.in2p3.fr/GammaLearn/GammaLearn/raw/master/share/lst_bootcamp_gl_data.tar.gz\n",
        "    !tar xvzf lst_bootcamp_gl_data.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "exps_path \u003d \u0027lst_bootcamp_gl_data/\u0027\n",
        "camera_parameters_path \u003d exps_path + \u0027camera_parameters.h5\u0027"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "### Regression model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "exp_name \u003d \u0027regression\u0027\n",
        "regression_network \u003d load_model(exps_path, exp_name, 100, camera_parameters_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "### Classification model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "exp_name \u003d \u0027classification\u0027\n",
        "classification_network \u003d load_model(exps_path, exp_name, 60, camera_parameters_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## R0 to DL2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "dl1_container \u003d DL1ParametersContainer() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "pycharm": {}
      },
      "outputs": [],
      "source": "with HDF5TableWriter(filename\u003ddl1_parameters_filename, group_name\u003d\u0027events\u0027, overwrite\u003dTrue) as writer:\n\n    source \u003d event_source(infile)\n    source.allowed_tels \u003d allowed_tels\n    source.max_events \u003d max_events\n\n    for i, event in enumerate(source):\n        if i%100\u003d\u003d0:\n            print(i)\n        cal(event)\n\n        for telescope_id, dl1 in event.dl1.tel.items():\n            tel \u003d event.inst.subarray.tels[telescope_id]\n            camera \u003d tel.camera\n\n            image \u003d dl1.image\n            peakpos \u003d dl1.pulse_time\n\n            data \u003d torch.tensor([image, peakpos], dtype\u003dtorch.float).unsqueeze(0)\n            prediction \u003d regression_network(data).squeeze(0).detach().numpy()\n            particle_prediction \u003d classification_network(data)\n            particle \u003d torch.max(particle_prediction, 1)[1]\n\n            ## Fill container ##\n            dl1_container.fill_mc(event)\n            dl1_container.fill_event_info(event)\n            dl1_container.set_mc_core_distance(event, telescope_id)\n            dl1_container.set_source_camera_position(event, telescope_id)\n            \n            event.dl2.energy[\u0027gl\u0027].energy \u003d 10**prediction[0] * units.TeV\n            event.dl2.shower[\u0027gl\u0027].core_x \u003d prediction[1] * units.km\n            event.dl2.shower[\u0027gl\u0027].core_y \u003d prediction[2] * units.km\n            event.dl2.shower[\u0027gl\u0027].alt \u003d prediction[3] * units.rad\n            event.dl2.shower[\u0027gl\u0027].az \u003d prediction[4] * units.rad\n            event.dl2.classification[\u0027gl\u0027].prediction \u003d particle.item()\n\n            ## Save parameters for later training ##\n            writer.write(camera.cam_id, [dl1_container, event.dl2.energy[\u0027gl\u0027], event.dl2.shower[\u0027gl\u0027],\n                                        event.dl2.classification[\u0027gl\u0027]])\n                \n                "
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "# The file has been created\n",
        "!ls -lsh dl1.h5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Loading hdf5 file is very easy with pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df \u003d pd.read_hdf(dl1_parameters_filename, key\u003d\u0027events/LSTCam\u0027)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "df"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}